# AI Chat Application

Полнофункциональное веб-приложение в стиле ChatGPT с поддержкой нескольких AI моделей, генерации изображений и мультимодального ввода.

## Описание проекта

Это современное AI чат-приложение, которое предоставляет пользователям доступ к различным моделям искусственного интеллекта через единый интерфейс с темной темой по умолчанию.

## Основные возможности

### 1. Мультимодельная поддержка
- **GPT-5** - самая умная модель OpenAI с конфигурируемым рассуждением (gpt-5-2025-08-07)
- **GPT-5 Mini** - быстрая версия с балансом производительности (gpt-5-mini-2025-08-07)
- **o3-mini** - специализация на STEM: математика, наука, код (o3-mini-2025-01-31)
- **Gemini** - мультимодальная модель Google (Gemini 2.5 Pro)

### 2. Генерация изображений
- Генерация изображений через Gemini Imagen 3 Fast
- Модель: `imagen-3.0-fast-generate-001`
- Интеграция сгенерированных изображений в чат
- Высокое качество результатов

### 3. Мультимодальный ввод
- **Текстовый ввод** - основной способ общения
- **Голосовой ввод** - кнопка микрофона появляется когда поле ввода пустое (как в Telegram)
  - Распознавание речи через Web Speech API
  - Автоматически переключается на кнопку отправки при вводе текста
- **Загрузка изображений** - анализ изображений с помощью vision capabilities
- **Загрузка файлов** - обработка PDF и текстовых документов

### 4. Веб-поиск
- Автоматический поиск в интернете при необходимости
- Интеграция с Tavily API для получения актуальной информации
- AI сам решает, когда нужен поиск в интернете
- Отображение процесса поиска пользователю

### 5. Streaming ответов
- Ответы AI отображаются в реальном времени
- Плавная анимация печатания текста
- Индикатор загрузки во время обработки

### 6. История разговоров
- Сохранение всех разговоров в памяти
- Группировка по датам (Сегодня, Вчера, На этой неделе, Ранее)
- Удобное переключение между разговорами
- Выбор модели при создании нового чата

## Технический стек

### Frontend
- **React** с TypeScript
- **Tailwind CSS** для стилизации
- **Shadcn UI** - готовые компоненты
- **React Markdown** - рендеринг markdown
- **Wouter** - роутинг
- **TanStack Query** - управление состоянием сервера

### Backend
- **Express.js** - веб-сервер
- **OpenAI SDK** - интеграция с GPT моделями
- **Google Generative AI SDK** - интеграция с Gemini
- **Tavily SDK** - веб-поиск для AI агентов
- **Multer** - обработка загрузки файлов
- **PDF Parse** - парсинг PDF документов

### Хранилище данных
- **localStorage** - локальное хранение разговоров в браузере
- Каждое устройство имеет изолированные данные
- Нет синхронизации между устройствами

## Архитектура

### Структура файлов

```
client/
  src/
    components/
      - ThemeProvider.tsx       # Управление темой
      - ThemeToggle.tsx         # Переключатель темы
      - NewChatDialog.tsx       # Диалог выбора модели при создании чата
      - ChatMessage.tsx         # Компонент сообщения
      - ChatInput.tsx           # Поле ввода с вложениями
      - VoiceInput.tsx          # Голосовой ввод
      - ImageGenerator.tsx      # Генерация изображений
      - ConversationList.tsx    # Список разговоров
      - AppSidebar.tsx          # Боковая панель
      ui/                       # Shadcn UI компоненты
    pages/
      - Chat.tsx                # Главная страница чата
    lib/
      - api.ts                  # API клиент для AI чата
      - storage.ts              # localStorage утилиты
      - queryClient.ts          # TanStack Query настройка
    App.tsx                     # Основное приложение
    
server/
  - routes.ts                   # AI chat API endpoints
  - index.ts                    # Express сервер
  
shared/
  - schema.ts                   # Общие типы и схемы
```

### API Endpoints

#### POST /api/chat
Отправка сообщения к AI и получение streaming ответа
- Поддерживает multipart/form-data для файлов
- Возвращает SSE stream для реал-тайм ответов
- Принимает: model, messages (история), content, images, files

```json
{
  "model": "gpt-5" | "gpt-5-mini" | "o3-mini" | "gemini",
  "messages": [...], // история сообщений
  "content": [...],  // текущее сообщение
  "images": [...],   // base64 изображения
}
```

#### POST /api/generate-image
Генерация изображения через Gemini Imagen
```json
{
  "prompt": "описание изображения"
}
```

## Переменные окружения

Приложение требует следующие секреты:

- `OPENAI_API_KEY` - API ключ OpenAI для доступа к GPT моделям
- `GEMINI_API_KEY` - API ключ Google для Gemini и генерации изображений
- `TAVILY_API_KEY` - API ключ Tavily для веб-поиска (1000 бесплатных запросов/месяц)
- `SESSION_SECRET` - секрет для сессий (уже настроен)

## Особенности реализации

### Локальное хранилище
- Все разговоры хранятся в localStorage браузера
- Каждое устройство имеет свои изолированные данные
- Нет синхронизации между устройствами
- При первом запуске предлагается создать чат
- Невозможно отправить сообщение без активного чата

### Темная тема по умолчанию
Приложение автоматически загружается в темной теме с возможностью переключения на светлую.

### Динамическое расширение поля ввода
Поле ввода автоматически расширяется при вводе текста:
- До 50% высоты экрана на десктопе
- До 70% высоты экрана на мобильных устройствах

### Горячие клавиши
- **Ctrl+Enter** - отправка сообщения
- Обычный Enter создает новую строку

### Обработка файлов
- **Изображения** - конвертируются в base64 для отправки к AI
- **PDF** - извлекается текст для анализа
- **Текстовые файлы** - читаются и добавляются к контексту

### Vision Capabilities
Все модели поддерживают анализ изображений:
- Загруженные пользователем изображения
- Сгенерированные изображения
- Изображения из интернета (через URL)

## Запуск проекта

Проект автоматически запускается через workflow "Start application", который выполняет:
```bash
npm run dev
```

Это запускает:
- Express сервер на порту 5000
- Vite dev server для frontend
- Все на одном порту благодаря Vite middleware

## Будущие улучшения

- Персистентное хранилище (PostgreSQL)
- Множественные чат-сессии с поиском
- Экспорт разговоров в различных форматах
- Расширенная поддержка файлов (Excel, архивы)
- Настройка параметров моделей (temperature, max tokens)
- Кастомные system prompts
- Авторизация пользователей
